# ‡∏ä‡∏∏‡∏î‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á: Face Analysis & Enhanced Registration
## ‡∏£‡∏∞‡∏ö‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏£‡∏ö‡∏ß‡∏á‡∏à‡∏£‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á

### üìã ‡∏™‡∏≤‡∏£‡∏ö‡∏±‡∏ç
7.1 [‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏° Enhanced Face Analysis](#71-‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°-enhanced-face-analysis)
7.2 [Face Analysis Service](#72-face-analysis-service)
7.3 [Enhanced Registration Service](#73-enhanced-registration-service)
7.4 [Quality Assessment System](#74-quality-assessment-system)
7.5 [Landmark Detection](#75-landmark-detection)
7.6 [API Endpoints](#76-api-endpoints)
7.7 [Frontend Integration](#77-frontend-integration)
7.8 [Performance Management](#78-performance-management)

---

## 7.1 ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏° Enhanced Face Analysis

‡∏£‡∏∞‡∏ö‡∏ö Face Analysis ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏£‡∏ö‡∏ß‡∏á‡∏à‡∏£‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏° Face Detection, Face Recognition, Quality Assessment ‡πÅ‡∏•‡∏∞ Enhanced Registration ‡πÑ‡∏ß‡πâ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÇ‡∏î‡∏¢‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ VRAM ‡πÅ‡∏•‡∏∞ Performance Optimization

### üèóÔ∏è ‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°
```
Face Analysis Service
‚îú‚îÄ‚îÄ Face Detection (YOLO Models)
‚îú‚îÄ‚îÄ Face Recognition (AdaFace/ArcFace/FaceNet)
‚îú‚îÄ‚îÄ Quality Assessment (Enhanced)
‚îú‚îÄ‚îÄ Landmark Detection (68 points)
‚îî‚îÄ‚îÄ Enhanced Registration (Validation)
```

### üéØ ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏´‡∏•‡∏±‡∏Å
- **Comprehensive Analysis**: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏£‡∏ö‡∏ß‡∏á‡∏à‡∏£
- **Quality Control**: ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô
- **Performance Optimization**: ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Memory ‡πÅ‡∏•‡∏∞ GPU ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
- **Enhanced Validation**: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Ç‡∏≠‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô

---

## 7.2 Face Analysis Service

### 7.2.1 Service Class
```python
from src.ai_services.face_analysis.face_analysis_service import FaceAnalysisService
from src.ai_services.face_analysis.models import AnalysisConfig, AnalysisMode

class FaceAnalysisService:
    """
    Enhanced Face Analysis Service
    ‡∏£‡∏ß‡∏° Face Detection + Face Recognition ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
    """
    
    def __init__(
        self,
        vram_manager=None,
        config=None,
        face_detection_service=None,
        face_recognition_service=None,
    ):
        self.vram_manager = vram_manager
        self.config = config or {}
        self.face_detection_service = face_detection_service
        self.face_recognition_service = face_recognition_service
        
        # Performance tracking
        self.stats = {
            "total_analyses": 0,
            "total_faces_detected": 0,
            "total_faces_recognized": 0,
            "processing_times": [],
            "success_rates": [],
        }
```

### 7.2.2 Analysis Configuration
```python
from src.ai_services.face_analysis.models import AnalysisConfig, AnalysisMode, QualityLevel

# Configuration options
config = AnalysisConfig(
    mode=AnalysisMode.FULL_ANALYSIS,  # DETECTION_ONLY, RECOGNITION_ONLY, FULL_ANALYSIS
    detection_model="yolo",
    recognition_model="adaface",
    confidence_threshold=0.7,
    min_face_size=30,
    max_faces=10,
    use_quality_based_selection=True,
    quality_level=QualityLevel.HIGH,
    include_landmarks=True,
    include_pose_analysis=True,
    include_age_gender=False,
    include_emotions=False,
)
```

### 7.2.3 ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Face Analysis
```python
async def analyze_faces_comprehensive(image_path: str):
    """‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏£‡∏ö‡∏ß‡∏á‡∏à‡∏£"""
    
    # Load image
    import cv2
    image = cv2.imread(image_path)
    
    # Create analysis config
    config = AnalysisConfig(
        mode=AnalysisMode.FULL_ANALYSIS,
        detection_model="yolov11m-face",
        recognition_model="adaface",
        confidence_threshold=0.8,
        min_face_size=50,
        use_quality_based_selection=True,
        include_landmarks=True,
        include_pose_analysis=True
    )
    
    # Perform analysis
    result = await face_analysis_service.analyze_faces(
        image=image,
        config=config,
        gallery=None  # ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡πà‡∏á gallery ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏î‡∏à‡∏≥
    )
    
    # Process results
    if result.success:
        print(f"‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤: {len(result.faces)} ‡∏´‡∏ô‡πâ‡∏≤")
        print(f"‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: {result.processing_time:.3f}s")
        
        for i, face in enumerate(result.faces):
            print(f"‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ {i+1}:")
            print(f"  - Confidence: {face.detection_confidence:.3f}")
            print(f"  - Quality Score: {face.quality_score:.3f}")
            print(f"  - Bounding Box: {face.bbox}")
            
            if face.recognition_result:
                print(f"  - ‡∏à‡∏î‡∏à‡∏≥‡πÑ‡∏î‡πâ: {face.recognition_result.person_name}")
                print(f"  - Similarity: {face.recognition_result.similarity:.3f}")
    else:
        print(f"‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {result.error}")
```

---

## 7.3 Enhanced Registration Service

### 7.3.1 Service Class
```python
from src.ai_services.face_analysis.enhanced_registration_service import EnhancedFaceRegistrationService

class EnhancedFaceRegistrationService:
    """Enhanced face registration with comprehensive quality checks"""
    
    def __init__(self, config=None):
        self.config = config or {}
        
        # Initialize quality assessment
        self.quality_assessor = EnhancedFaceQualityAssessment(
            self.config.get("quality", {})
        )
        
        # Initialize landmark detector
        self.landmark_detector = FaceLandmarkDetector()
        
        # Enhanced thresholds
        self.enhanced_thresholds = {
            "minimum_quality_score": 0.75,
            "strict_frontal_check": True,
            "require_landmarks": True,
            "max_pose_angle": 15.0,  # degrees
        }
```

### 7.3.2 ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Ç‡∏≠‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
```python
async def validate_registration_image_example():
    """‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô"""
    
    # Read image file
    with open("user_photo.jpg", "rb") as f:
        image_bytes = f.read()
    
    # Validate image
    validation_result = await enhanced_registration_service.validate_registration_image(
        image_bytes=image_bytes,
        person_id="user123",
        strict_mode=True
    )
    
    if validation_result["success"]:
        print("‚úÖ ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô")
        
        # Quality metrics
        quality = validation_result["quality_assessment"]
        print(f"‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û: {quality['overall_score']:.3f}")
        print(f"‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏î: {quality['sharpness_score']:.3f}")
        print(f"‡πÅ‡∏™‡∏á‡∏™‡∏ß‡πà‡∏≤‡∏á: {quality['brightness_score']:.3f}")
        
        # Landmark analysis
        landmarks = validation_result["landmark_analysis"]
        if landmarks["landmarks_found"]:
            print(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Landmarks: {landmarks['landmark_count']}")
            print(f"‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏±‡∏ô‡∏ï‡∏£‡∏á: {landmarks['is_frontal']}")
        
        # Pose analysis
        pose = validation_result["pose_analysis"]
        print(f"‡∏°‡∏∏‡∏°‡∏Å‡∏≤‡∏£‡∏´‡∏±‡∏ô - Yaw: {pose['yaw_angle']:.1f}¬∞, Pitch: {pose['pitch_angle']:.1f}¬∞")
    
    else:
        print("‚ùå ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô")
        print(f"‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•: {validation_result['error']}")
        
        # Recommendations
        for recommendation in validation_result["recommendations"]:
            print(f"üí° {recommendation}")
```

### 7.3.3 Enhanced Registration Workflow
```python
async def enhanced_registration_workflow(person_id: str, person_name: str, image_bytes: bytes):
    """Workflow ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á"""
    
    # Step 1: Validate image quality
    validation_result = await enhanced_registration_service.validate_registration_image(
        image_bytes=image_bytes,
        person_id=person_id,
        strict_mode=True
    )
    
    if not validation_result["success"]:
        return {
            "success": False,
            "stage": "validation",
            "error": validation_result["error"],
            "recommendations": validation_result["recommendations"]
        }
    
    # Step 2: Extract face embedding
    img_buffer = np.frombuffer(image_bytes, np.uint8)
    image = cv2.imdecode(img_buffer, cv2.IMREAD_COLOR)
    
    # Detect and extract best face
    detection_result = await face_detection_service.detect_faces(
        image=image,
        model_name="yolov11m-face",
        conf_threshold=0.8,
        min_quality_threshold=70.0,
        return_landmarks=True
    )
    
    if not detection_result.faces:
        return {
            "success": False,
            "stage": "detection",
            "error": "‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û"
        }
    
    # Get best quality face
    best_face = max(detection_result.faces, key=lambda f: f.quality_score)
    
    # Step 3: Generate embedding
    embedding_result = await face_recognition_service.extract_embedding(
        face_image=best_face.cropped_face,
        model_name="adaface"
    )
    
    if not embedding_result.success:
        return {
            "success": False,
            "stage": "embedding",
            "error": "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á embedding ‡πÑ‡∏î‡πâ"
        }
    
    # Step 4: Save to database (pseudo-code)
    registration_data = {
        "person_id": person_id,
        "person_name": person_name,
        "embedding": embedding_result.embedding.tolist(),
        "model_used": embedding_result.model_used,
        "quality_score": best_face.quality_score,
        "validation_metrics": validation_result,
        "bbox": [best_face.x1, best_face.y1, best_face.x2, best_face.y2],
        "landmarks": best_face.landmarks if hasattr(best_face, 'landmarks') else None
    }
    
    # await database.save_face_registration(registration_data)
    
    return {
        "success": True,
        "person_id": person_id,
        "quality_score": best_face.quality_score,
        "model_used": embedding_result.model_used,
        "validation_summary": validation_result["quality_assessment"]
    }
```

---

## 7.4 Quality Assessment

### 7.4.1 Enhanced Quality Assessment
```python
from src.ai_services.face_detection.enhanced_quality_assessment import EnhancedFaceQualityAssessment

class EnhancedFaceQualityAssessment:
    """Comprehensive face quality assessment"""
    
    def assess_face_quality(self, image, use_landmarks=True):
        """‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏£‡∏ö‡∏ß‡∏á‡∏à‡∏£"""
        
        quality_metrics = {
            "sharpness_score": self._calculate_sharpness(image),
            "brightness_score": self._assess_brightness(image),
            "contrast_score": self._assess_contrast(image),
            "blur_score": self._detect_motion_blur(image),
            "noise_score": self._assess_noise_level(image),
            "exposure_score": self._assess_exposure(image),
        }
        
        if use_landmarks:
            landmark_metrics = self._assess_landmark_quality(image)
            quality_metrics.update(landmark_metrics)
        
        return quality_metrics
    
    def get_quality_summary(self, quality_metrics):
        """‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û"""
        
        # Calculate overall score
        weights = {
            "sharpness_score": 0.25,
            "brightness_score": 0.15,
            "contrast_score": 0.15,
            "blur_score": 0.20,
            "noise_score": 0.10,
            "exposure_score": 0.15
        }
        
        overall_score = sum(
            quality_metrics.get(metric, 0.0) * weight
            for metric, weight in weights.items()
        )
        
        return {
            "overall_score": overall_score,
            "quality_level": self._get_quality_level(overall_score),
            "individual_scores": quality_metrics,
            "recommendations": self._generate_recommendations(quality_metrics)
        }
```

### 7.4.2 Quality Metrics Examples
```python
async def assess_image_quality_example(image_path: str):
    """‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û"""
    
    image = cv2.imread(image_path)
    
    # Assess quality
    quality_metrics = quality_assessor.assess_face_quality(
        image=image,
        use_landmarks=True
    )
    
    summary = quality_assessor.get_quality_summary(quality_metrics)
    
    print(f"‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏£‡∏ß‡∏°: {summary['overall_score']:.3f}")
    print(f"‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û: {summary['quality_level']}")
    
    print("\n‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏î‡πâ‡∏≤‡∏ô:")
    for metric, score in summary['individual_scores'].items():
        print(f"  {metric}: {score:.3f}")
    
    print("\n‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏∞‡πÅ‡∏ô‡∏∞:")
    for recommendation in summary['recommendations']:
        print(f"  üí° {recommendation}")
```

---

## 7.5 Landmark Detection

### 7.5.1 Landmark Detection Service
```python
from src.ai_services.face_detection.landmark_detector import FaceLandmarkDetector

class FaceLandmarkDetector:
    """Face landmark detection and analysis"""
    
    def detect_landmarks(self, image, detailed=True):
        """‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö landmarks ‡∏Ç‡∏≠‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ (68 ‡∏à‡∏∏‡∏î)"""
        
        results = []
        faces = self.face_cascade.detectMultiScale(image)
        
        for (x, y, w, h) in faces:
            face_roi = image[y:y+h, x:x+w]
            
            # Detect 68 landmarks
            landmarks = self._detect_68_landmarks(face_roi)
            
            if landmarks is not None:
                # Adjust coordinates to full image
                adjusted_landmarks = self._adjust_landmarks_to_full_image(
                    landmarks, x, y
                )
                
                face_data = {
                    "bbox": [x, y, x+w, y+h],
                    "landmarks": adjusted_landmarks,
                    "landmark_count": len(adjusted_landmarks)
                }
                
                if detailed:
                    face_data.update(self._analyze_face_geometry(adjusted_landmarks))
                
                results.append(face_data)
        
        return results
    
    def is_frontal_face(self, face_data, max_angle=15.0):
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏±‡∏ô‡∏ï‡∏£‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
        
        landmarks = face_data.get("landmarks", [])
        if len(landmarks) < 68:
            return False
        
        # Calculate pose angles
        pose_angles = self._calculate_pose_angles(landmarks)
        
        return (
            abs(pose_angles["yaw"]) <= max_angle and
            abs(pose_angles["pitch"]) <= max_angle and
            abs(pose_angles["roll"]) <= max_angle
        )
```

### 7.5.2 Pose Analysis
```python
async def analyze_face_pose_example(image_path: str):
    """‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡πà‡∏≤‡∏ó‡∏≤‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤"""
    
    image = cv2.imread(image_path)
    
    # Detect landmarks
    landmark_results = landmark_detector.detect_landmarks(
        image=image,
        detailed=True
    )
    
    if landmark_results:
        for i, face in enumerate(landmark_results):
            print(f"‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ {i+1}:")
            print(f"  ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Landmarks: {face['landmark_count']}")
            
            # Pose analysis
            if "pose_analysis" in face:
                pose = face["pose_analysis"]
                print(f"  ‡∏°‡∏∏‡∏°‡∏Å‡∏≤‡∏£‡∏´‡∏±‡∏ô:")
                print(f"    Yaw (‡∏ã‡πâ‡∏≤‡∏¢-‡∏Ç‡∏ß‡∏≤): {pose['yaw_angle']:.1f}¬∞")
                print(f"    Pitch (‡∏Ç‡∏∂‡πâ‡∏ô-‡∏•‡∏á): {pose['pitch_angle']:.1f}¬∞")
                print(f"    Roll (‡πÄ‡∏≠‡∏µ‡∏¢‡∏á): {pose['roll_angle']:.1f}¬∞")
            
            # Check if frontal
            is_frontal = landmark_detector.is_frontal_face(face)
            print(f"  ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏±‡∏ô‡∏ï‡∏£‡∏á: {'‚úÖ' if is_frontal else '‚ùå'}")
            
            # Face geometry
            if "face_geometry" in face:
                geometry = face["face_geometry"]
                print(f"  ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤: {geometry['face_width']:.1f}px")
                print(f"  ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤: {geometry['face_height']:.1f}px")
                print(f"  ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô: {geometry['face_ratio']:.2f}")
```

---

## 7.6 API Endpoints

### 7.6.1 Complete Analysis Endpoint
```python
from src.api.complete_endpoints import face_analysis_router

@face_analysis_router.post("/analyze/comprehensive")
async def comprehensive_face_analysis(
    request: FaceAnalysisJSONRequest,
    face_analysis_service = Depends(get_face_analysis_service)
):
    """API ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏£‡∏ö‡∏ß‡∏á‡∏à‡∏£"""
    
    try:
        # Decode image
        image = decode_base64_image(request.image_base64)
        
        # Create analysis config
        config = AnalysisConfig(
            mode=AnalysisMode.FULL_ANALYSIS,
            **request.config or {}
        )
        
        # Perform analysis
        result = await face_analysis_service.analyze_faces(
            image=image,
            config=config,
            gallery=request.gallery
        )
        
        return {
            "success": result.success,
            "faces": [face.to_dict() for face in result.faces],
            "processing_time": result.processing_time,
            "model_info": result.model_info,
            "stats": result.stats
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@face_analysis_router.post("/register/enhanced")
async def enhanced_face_registration(
    person_id: str = Form(...),
    person_name: str = Form(...),
    image: UploadFile = File(...),
    strict_mode: bool = Form(True),
    enhanced_registration_service = Depends(get_enhanced_registration_service)
):
    """API ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á"""
    
    try:
        # Read image
        image_bytes = await image.read()
        
        # Validate and register
        result = await enhanced_registration_service.validate_registration_image(
            image_bytes=image_bytes,
            person_id=person_id,
            strict_mode=strict_mode
        )
        
        if result["success"]:
            # Proceed with registration
            registration_result = await enhanced_registration_workflow(
                person_id=person_id,
                person_name=person_name,
                image_bytes=image_bytes
            )
            return registration_result
        else:
            return result
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

---

## 7.7 ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏ô Frontend

### ‚öõÔ∏è React Hook ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Enhanced Analysis
```typescript
// hooks/useEnhancedFaceAnalysis.ts
import { useState, useCallback } from 'react';

interface AnalysisConfig {
  mode: 'detection_only' | 'recognition_only' | 'full_analysis';
  detection_model?: string;
  recognition_model?: string;
  confidence_threshold?: number;
  include_landmarks?: boolean;
  include_pose_analysis?: boolean;
}

interface AnalysisResult {
  success: boolean;
  faces: FaceResult[];
  processing_time: number;
  model_info: any;
  stats: any;
}

export const useEnhancedFaceAnalysis = () => {
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [result, setResult] = useState<AnalysisResult | null>(null);
  const [error, setError] = useState<string | null>(null);

  const analyzeImage = useCallback(async (
    imageFile: File,
    config: AnalysisConfig = { mode: 'full_analysis' }
  ) => {
    setIsAnalyzing(true);
    setError(null);

    try {
      // Convert image to base64
      const base64 = await new Promise<string>((resolve) => {
        const reader = new FileReader();
        reader.onload = () => {
          const result = reader.result as string;
          resolve(result.split(',')[1]); // Remove data:image/jpeg;base64, prefix
        };
        reader.readAsDataURL(imageFile);
      });

      // Call API
      const response = await fetch('/api/face-analysis/analyze/comprehensive', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          image_base64: base64,
          mode: config.mode,
          config: config,
        }),
      });

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }

      const analysisResult = await response.json();
      setResult(analysisResult);

    } catch (err) {
      setError(err instanceof Error ? err.message : '‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß');
    } finally {
      setIsAnalyzing(false);
    }
  }, []);

  return {
    analyzeImage,
    isAnalyzing,
    result,
    error,
    clearResult: () => setResult(null),
    clearError: () => setError(null),
  };
};
```

### üéØ Enhanced Registration Component
```typescript
// components/EnhancedFaceRegistration.tsx
import React, { useState } from 'react';
import { useEnhancedFaceAnalysis } from '../hooks/useEnhancedFaceAnalysis';

interface RegistrationProps {
  onSuccess: (result: any) => void;
  onError: (error: string) => void;
}

export const EnhancedFaceRegistration: React.FC<RegistrationProps> = ({
  onSuccess,
  onError,
}) => {
  const [personId, setPersonId] = useState('');
  const [personName, setPersonName] = useState('');
  const [selectedImage, setSelectedImage] = useState<File | null>(null);
  const [previewUrl, setPreviewUrl] = useState<string | null>(null);
  const [isRegistering, setIsRegistering] = useState(false);
  const [validationResult, setValidationResult] = useState<any>(null);

  const { analyzeImage, isAnalyzing } = useEnhancedFaceAnalysis();

  const handleImageSelect = (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (file) {
      setSelectedImage(file);
      setPreviewUrl(URL.createObjectURL(file));
      
      // Auto-validate image quality
      analyzeImage(file, {
        mode: 'detection_only',
        include_landmarks: true,
        include_pose_analysis: true,
      }).then((result) => {
        if (result) {
          setValidationResult(result);
        }
      });
    }
  };

  const handleRegistration = async () => {
    if (!selectedImage || !personId || !personName) {
      onError('‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô');
      return;
    }

    setIsRegistering(true);

    try {
      const formData = new FormData();
      formData.append('person_id', personId);
      formData.append('person_name', personName);
      formData.append('image', selectedImage);
      formData.append('strict_mode', 'true');

      const response = await fetch('/api/face-analysis/register/enhanced', {
        method: 'POST',
        body: formData,
      });

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }

      const result = await response.json();
      
      if (result.success) {
        onSuccess(result);
      } else {
        onError(result.error || '‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß');
      }

    } catch (err) {
      onError(err instanceof Error ? err.message : '‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î');
    } finally {
      setIsRegistering(false);
    }
  };

  return (
    <div className="enhanced-registration">
      <h3>‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á</h3>
      
      {/* Form fields */}
      <div className="form-group">
        <label>‡∏£‡∏´‡∏±‡∏™‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•:</label>
        <input
          type="text"
          value={personId}
          onChange={(e) => setPersonId(e.target.value)}
          placeholder="‡πÄ‡∏ä‡πà‡∏ô USER001"
        />
      </div>

      <div className="form-group">
        <label>‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•:</label>
        <input
          type="text"
          value={personName}
          onChange={(e) => setPersonName(e.target.value)}
          placeholder="‡πÄ‡∏ä‡πà‡∏ô ‡∏ô‡∏≤‡∏¢ ‡∏™‡∏°‡∏ä‡∏≤‡∏¢ ‡πÉ‡∏à‡∏î‡∏µ"
        />
      </div>

      {/* Image upload */}
      <div className="form-group">
        <label>‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤:</label>
        <input
          type="file"
          accept="image/*"
          onChange={handleImageSelect}
        />
      </div>

      {/* Image preview */}
      {previewUrl && (
        <div className="image-preview">
          <img src={previewUrl} alt="Preview" style={{ maxWidth: '300px' }} />
        </div>
      )}

      {/* Validation results */}
      {validationResult && (
        <div className="validation-results">
          <h4>‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û:</h4>
          {validationResult.faces?.length > 0 ? (
            <div className="quality-info">
              <p>‚úÖ ‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤: {validationResult.faces.length} ‡∏´‡∏ô‡πâ‡∏≤</p>
              {validationResult.faces.map((face: any, index: number) => (
                <div key={index} className="face-info">
                  <p>‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à: {(face.detection_confidence * 100).toFixed(1)}%</p>
                  <p>‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û: {(face.quality_score * 100).toFixed(1)}%</p>
                  {face.pose_analysis && (
                    <p>‡∏°‡∏∏‡∏°‡∏Å‡∏≤‡∏£‡∏´‡∏±‡∏ô: {Math.abs(face.pose_analysis.yaw_angle).toFixed(1)}¬∞</p>
                  )}
                </div>
              ))}
            </div>
          ) : (
            <p className="error">‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û</p>
          )}
        </div>
      )}

      {/* Action buttons */}
      <div className="actions">
        <button
          onClick={handleRegistration}
          disabled={isRegistering || isAnalyzing || !selectedImage}
          className="register-btn"
        >
          {isRegistering ? '‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô...' : '‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô'}
        </button>
      </div>

      {/* Loading indicator */}
      {(isAnalyzing || isRegistering) && (
        <div className="loading">
          <p>‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•...</p>
        </div>
      )}
    </div>
  );
};
```

---

## 7.8 ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Performance

### ‚ö° Performance Monitoring
```python
async def monitor_analysis_performance():
    """‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° Performance"""
    
    # Get service stats
    stats = face_analysis_service.stats
    
    print("üìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:")
    print(f"  ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {stats['total_analyses']}")
    print(f"  ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö: {stats['total_faces_detected']}")
    print(f"  ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏î‡∏à‡∏≥‡πÑ‡∏î‡πâ: {stats['total_faces_recognized']}")
    
    if stats['processing_times']:
        avg_time = sum(stats['processing_times']) / len(stats['processing_times'])
        print(f"  ‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {avg_time:.3f}s")
    
    if stats['success_rates']:
        avg_success = sum(stats['success_rates']) / len(stats['success_rates'])
        print(f"  ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {avg_success:.1%}")

# ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° VRAM
async def monitor_vram_usage():
    """‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° VRAM usage"""
    
    if vram_manager:
        vram_info = await vram_manager.get_memory_info()
        print("üîß ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ VRAM:")
        print(f"  VRAM ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {vram_info['total_vram_gb']:.1f} GB")
        print(f"  VRAM ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ: {vram_info['allocated_vram_gb']:.1f} GB")
        print(f"  VRAM ‡∏ß‡πà‡∏≤‡∏á: {vram_info['free_vram_gb']:.1f} GB")
        print(f"  ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô: {vram_info['usage_percentage']:.1f}%")
```

### üéØ Performance Optimization Tips

1. **Batch Processing**: ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô
2. **Model Caching**: Cache ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ô VRAM ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡πÄ‡∏ß‡∏•‡∏≤ loading
3. **Quality Pre-filtering**: ‡∏Å‡∏£‡∏≠‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏ï‡πà‡∏≥‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á‡πÑ‡∏õ recognition
4. **Async Processing**: ‡πÉ‡∏ä‡πâ asynchronous processing ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö batch operations
5. **Memory Management**: ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ VRAM ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û

---

## ‡∏™‡∏£‡∏∏‡∏õ

‡∏£‡∏∞‡∏ö‡∏ö Face Analysis & Enhanced Registration ‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏£‡∏ö‡∏ß‡∏á‡∏à‡∏£ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á:

### ‚úÖ ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏´‡∏•‡∏±‡∏Å
- **Comprehensive Analysis**: ‡∏£‡∏ß‡∏° Detection + Recognition + Quality Assessment
- **Enhanced Registration**: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡πà‡∏≠‡∏ô‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô  
- **Quality Control**: ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
- **Performance Monitoring**: ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÅ‡∏•‡∏∞ VRAM usage
- **Flexible Configuration**: ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£

### üéØ ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ
- ‡∏£‡∏∞‡∏ö‡∏ö‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Access Control
- ‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏±‡∏á‡∏Ñ‡∏°‡∏Å‡∏±‡∏ö Face Tagging
- ‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ï‡∏±‡∏ß‡∏ï‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
- ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏Å‡∏•‡∏∏‡πà‡∏°

‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö Production
