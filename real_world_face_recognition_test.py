#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Real-world Face Recognition Test
‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö Face Recognition ‡πÅ‡∏ö‡∏ö‡∏à‡∏£‡∏¥‡∏á:
- ‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô 2 users (boss, night) ‡∏ù‡πÖ‡∏á 10 ‡∏†‡∏≤‡∏û‡∏ï‡πà‡∏≠‡∏Ñ‡∏ô
- ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏†‡∏≤‡∏û‡πÉ‡∏ô test_images
- ‡∏™‡∏£‡πâ‡∏≤‡∏á Ensemble model (FACENET 50%, ADAFACE 25%, ARCFACE 25%)
- Output ‡∏†‡∏≤‡∏û‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏£‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠
"""

import os
import json
import time
import base64
import requests
import numpy as np
import cv2
from typing import Dict, List, Any, Tuple
import logging
from collections import defaultdict

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Configuration
API_BASE_URL = "http://localhost:8080"
TEST_IMAGES_DIR = "test_images"
OUTPUT_DIR = "output/real_world_recognition"

# Users ‡πÅ‡∏•‡∏∞‡∏£‡∏π‡∏õ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô
USERS = {
    "boss": [f"boss_{i:02d}.jpg" for i in range(1, 11)],
    "night": [f"night_{i:02d}.jpg" for i in range(1, 11)]
}

MODELS = ["facenet", "adaface", "arcface"]

# Ensemble weights
ENSEMBLE_WEIGHTS = {
    "facenet": 0.5,
    "adaface": 0.25,
    "arcface": 0.25
}

def ensure_output_dir():
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå output"""
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    for model in MODELS + ["ensemble"]:
        model_dir = os.path.join(OUTPUT_DIR, model)
        os.makedirs(model_dir, exist_ok=True)
    logger.info(f"Output directory: {OUTPUT_DIR}")

def image_to_base64(image_path: str) -> str:
    """‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô base64"""
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode('utf-8')

def clear_database():
    """‡∏•‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏î‡∏™‡∏≠‡∏ö"""
    try:
        gallery_response = requests.get(f"{API_BASE_URL}/api/face-recognition/get-gallery", timeout=30)
        if gallery_response.status_code == 200:
            gallery = gallery_response.json()
            logger.info(f"üìã Current gallery has {len(gallery)} persons")
        return True
    except Exception as e:
        logger.error(f"‚ùå Cannot access database: {e}")
        return False

def register_all_users():
    """‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏î‡πâ‡∏ß‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ Individual Registration"""
    logger.info("üîÑ Starting Individual Registration for all users...")
    
    total_registrations = 0
    success_count = 0
    
    for user_id, image_files in USERS.items():
        logger.info(f"\nüë§ Registering user: {user_id}")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏£‡∏π‡∏õ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á
        available_images = []
        for img_file in image_files:
            img_path = os.path.join(TEST_IMAGES_DIR, img_file)
            if os.path.exists(img_path):
                available_images.append(img_file)
            else:
                logger.warning(f"‚ö†Ô∏è Image not found: {img_file}")
        
        if len(available_images) < 5:
            logger.error(f"‚ùå Not enough images for {user_id}: {len(available_images)}/10")
            raise Exception(f"Insufficient images for user {user_id}")
        
        logger.info(f"üìÅ Found {len(available_images)} images for {user_id}")
        
        # ‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ó‡∏µ‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•
        for model_name in MODELS:
            logger.info(f"  üß† Registering with {model_name} model...")
            
            model_success = 0
            for i, img_file in enumerate(available_images, 1):
                img_path = os.path.join(TEST_IMAGES_DIR, img_file)
                
                logger.info(f"    [{i}/{len(available_images)}] Processing: {img_file}")
                
                # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô base64
                image_base64 = image_to_base64(img_path)
                
                # ‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô
                success = add_single_face(image_base64, user_id, f"User {user_id.title()}", model_name)
                
                total_registrations += 1
                if success:
                    success_count += 1
                    model_success += 1
                    logger.info(f"      ‚úÖ Success")
                else:
                    logger.error(f"      ‚ùå Failed")
                    raise Exception(f"Registration failed for {user_id}/{img_file}/{model_name}")
                
                # ‡∏£‡∏≠‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
                time.sleep(1)
            
            logger.info(f"  üìä {model_name}: {model_success}/{len(available_images)} success")
    
    success_rate = (success_count / total_registrations) * 100 if total_registrations > 0 else 0
    logger.info(f"\n‚úÖ Registration completed: {success_count}/{total_registrations} ({success_rate:.1f}%)")
    
    if success_rate < 95:
        raise Exception(f"Registration success rate too low: {success_rate:.1f}%")
    
    return success_count, total_registrations

def add_single_face(image_base64: str, person_id: str, person_name: str, model_name: str) -> bool:
    """‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÄ‡∏Ç‡πâ‡∏≤‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    url = f"{API_BASE_URL}/api/face-recognition/add-face-json"
    
    data = {
        "person_id": person_id,
        "person_name": person_name,
        "face_image_base64": image_base64,
        "model_name": model_name
    }
    
    try:
        response = requests.post(url, json=data, timeout=120)
        if response.status_code == 200:
            result = response.json()
            return result.get('success', False)
        else:
            logger.error(f"‚ùå Registration failed: {response.status_code} - {response.text}")
            return False
    except Exception as e:
        logger.error(f"‚ùå Registration exception: {e}")
        return False

def get_all_test_images() -> List[str]:
    """‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏£‡∏π‡∏õ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô test_images"""
    if not os.path.exists(TEST_IMAGES_DIR):
        logger.error(f"‚ùå Test images directory not found: {TEST_IMAGES_DIR}")
        return []
    
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}
    test_images = []
    
    for file in os.listdir(TEST_IMAGES_DIR):
        if os.path.splitext(file.lower())[1] in image_extensions:
            test_images.append(file)
    
    test_images.sort()  # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏ä‡∏∑‡πà‡∏≠
    logger.info(f"üìÅ Found {len(test_images)} test images")
    
    return test_images

def recognize_face_all_models(image_base64: str, faces: List[Dict] = None) -> Dict[str, Any]:
    """‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏à‡∏î‡∏à‡∏≥‡∏î‡πâ‡∏ß‡∏¢‡∏ó‡∏∏‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤"""
    results = {}
    
    # ‡∏î‡∏∂‡∏á gallery
    try:
        gallery_response = requests.get(f"{API_BASE_URL}/api/face-recognition/get-gallery", timeout=30)
        if gallery_response.status_code != 200:
            logger.error("‚ùå Cannot get gallery")
            return {}
        gallery = gallery_response.json()
    except Exception as e:
        logger.error(f"‚ùå Gallery error: {e}")
        return {}
    
    if not gallery:
        logger.error("‚ùå Gallery is empty")
        return {}
    
    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ ‡πÉ‡∏´‡πâ recognize ‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡πÉ‡∏ö
    if not faces or len(faces) == 0:
        for model_name in MODELS:
            try:
                result = recognize_single_model(image_base64, model_name, gallery)
                results[model_name] = result
            except Exception as e:
                logger.error(f"‚ùå Recognition failed for {model_name}: {e}")
                results[model_name] = {"matches": [], "error": str(e)}
        return results
    
    # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤: ‡∏´‡∏≤‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏´‡∏ç‡πà‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (likely main subject)
    if len(faces) > 1:
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        face_areas = []
        for face in faces:
            bbox = face.get("bbox", {})
            width = bbox.get("x2", 0) - bbox.get("x1", 0)
            height = bbox.get("y2", 0) - bbox.get("y1", 0)
            area = width * height
            face_areas.append(area)
        
        # ‡∏´‡∏≤‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏´‡∏ç‡πà‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
        main_face_idx = face_areas.index(max(face_areas))
        logger.info(f"    üìè Multiple faces detected: Using largest face (#{main_face_idx+1}/{len(faces)})")
        
        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏Å‡∏•‡∏∏‡πà‡∏°: ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏Ñ‡∏£‡∏≠‡∏õ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å‡∏≠‡∏≠‡∏Å‡∏°‡∏≤
        main_face = faces[main_face_idx]
        try:
            cropped_base64 = crop_face_from_image(image_base64, main_face)
            if cropped_base64:
                image_base64 = cropped_base64
                logger.info(f"    ‚úÇÔ∏è Using cropped main face for recognition")
        except Exception as e:
            logger.warning(f"    ‚ö†Ô∏è Cannot crop face, using full image: {e}")
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏∏‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
    for model_name in MODELS:
        try:
            result = recognize_single_model(image_base64, model_name, gallery)
            results[model_name] = result
        except Exception as e:
            logger.error(f"‚ùå Recognition failed for {model_name}: {e}")
            results[model_name] = {"matches": [], "error": str(e)}
    
    return results

def recognize_single_model(image_base64: str, model_name: str, gallery: Dict[str, Any]) -> Dict[str, Any]:
    """‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏à‡∏î‡∏à‡∏≥‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏î‡∏µ‡∏¢‡∏ß"""
    url = f"{API_BASE_URL}/api/face-recognition/recognize"
    
    data = {
        "face_image_base64": image_base64,
        "gallery": gallery,
        "model_name": model_name,
        "top_k": 5,
        "similarity_threshold": 0.3
    }
    
    try:
        response = requests.post(url, json=data, timeout=60)
        if response.status_code == 200:
            return response.json()
        else:
            logger.error(f"‚ùå Recognition failed: {response.status_code}")
            return {"matches": [], "error": f"HTTP {response.status_code}"}
    except Exception as e:
        logger.error(f"‚ùå Recognition exception: {e}")
        return {"matches": [], "error": str(e)}

def create_ensemble_prediction(model_results: Dict[str, Any]) -> Dict[str, Any]:
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÅ‡∏ö‡∏ö Ensemble"""
    if not model_results:
        return {"matches": [], "method": "ensemble"}
    
    # ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
    person_scores = defaultdict(list)
    
    for model_name, result in model_results.items():
        if "matches" in result and result["matches"]:
            weight = ENSEMBLE_WEIGHTS.get(model_name, 0)
            
            for match in result["matches"]:
                person_id = match.get("person_id", "")
                similarity = match.get("similarity", 0.0)
                weighted_score = similarity * weight
                
                person_scores[person_id].append({
                    "model": model_name,
                    "similarity": similarity,
                    "weighted_score": weighted_score,
                    "weight": weight
                })
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏£‡∏ß‡∏°
    ensemble_matches = []
    for person_id, scores in person_scores.items():
        total_weighted_score = sum(score["weighted_score"] for score in scores)
        total_weight = sum(score["weight"] for score in scores)
        
        if total_weight > 0:
            final_score = total_weighted_score / total_weight
            
            ensemble_matches.append({
                "person_id": person_id,
                "similarity": final_score,
                "contributing_models": len(scores),
                "model_details": scores
            })
    
    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô
    ensemble_matches.sort(key=lambda x: x["similarity"], reverse=True)
    
    return {
        "matches": ensemble_matches,
        "method": "ensemble",
        "weights_used": ENSEMBLE_WEIGHTS
    }

def detect_faces(image_base64: str) -> List[Dict[str, Any]]:
    """‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û"""
    url = f"{API_BASE_URL}/api/face-detection/detect-base64"
    
    data = {
        "image_base64": image_base64,
        "model_name": "yolov11m-face",
        "confidence_threshold": 0.5
    }
    
    try:
        response = requests.post(url, json=data, timeout=60)
        if response.status_code == 200:
            result = response.json()
            return result.get("faces", [])
        else:
            logger.error(f"‚ùå Face detection failed: {response.status_code}")
            return []
    except Exception as e:
        logger.error(f"‚ùå Face detection exception: {e}")
        return []

def draw_results_on_image(image_path: str, faces: List[Dict], recognition_results: Dict[str, Any], model_name: str) -> str:
    """‡∏ß‡∏≤‡∏î‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏à‡∏î‡∏à‡∏≥‡∏ö‡∏ô‡∏†‡∏≤‡∏û"""
    # ‡∏≠‡πà‡∏≤‡∏ô‡∏†‡∏≤‡∏û
    image = cv2.imread(image_path)
    if image is None:
        logger.error(f"‚ùå Cannot read image: {image_path}")
        return ""
    
    original_height, original_width = image.shape[:2]
    
    # ‡πÉ‡∏ä‡πâ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏à‡∏î‡∏à‡∏≥‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏
    matches = recognition_results.get("matches", [])
    recognized_person = matches[0].get("person_id", "unknown") if matches else "unknown"
    similarity = matches[0].get("similarity", 0.0) if matches else 0.0
    
    # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠
    for i, face in enumerate(faces):
        # ‡∏î‡∏∂‡∏á‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        bbox = face.get("bbox", {})
        x1 = int(bbox.get("x1", 0))
        y1 = int(bbox.get("y1", 0))
        x2 = int(bbox.get("x2", 0))
        y2 = int(bbox.get("y2", 0))
        
        # ‡∏™‡∏µ‡∏Å‡∏£‡∏≠‡∏ö (‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß = ‡∏à‡∏î‡∏à‡∏≥‡πÑ‡∏î‡πâ, ‡πÅ‡∏î‡∏á = ‡πÑ‡∏°‡πà‡∏à‡∏î‡∏à‡∏≥‡πÑ‡∏î‡πâ)
        color = (0, 255, 0) if recognized_person != "unknown" else (0, 0, 255)
        
        # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö
        cv2.rectangle(image, (x1, y1), (x2, y2), color, 3)
        
        # ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
        label = f"{recognized_person} ({similarity:.3f})" if recognized_person != "unknown" else "Unknown"
        model_text = f"Model: {model_name.upper()}"
        
        # ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.7
        thickness = 2
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
        (label_w, label_h), _ = cv2.getTextSize(label, font, font_scale, thickness)
        (model_w, model_h), _ = cv2.getTextSize(model_text, font, font_scale, thickness)
        
        # ‡∏ß‡∏≤‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
        cv2.rectangle(image, (x1, y1 - label_h - model_h - 10), 
                     (x1 + max(label_w, model_w) + 10, y1), color, -1)
        
        # ‡∏ß‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
        cv2.putText(image, label, (x1 + 5, y1 - model_h - 5), 
                   font, font_scale, (255, 255, 255), thickness)
        cv2.putText(image, model_text, (x1 + 5, y1 - 5), 
                   font, font_scale, (255, 255, 255), thickness)
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏ï‡πá‡∏°)
    output_filename = f"{os.path.splitext(os.path.basename(image_path))[0]}_{model_name}.jpg"
    output_path = os.path.join(OUTPUT_DIR, model_name, output_filename)
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á
    cv2.imwrite(output_path, image, [cv2.IMWRITE_JPEG_QUALITY, 95])
    
    return output_path

def run_real_world_test():
    """‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏ö‡∏ö‡∏à‡∏£‡∏¥‡∏á"""
    logger.info("üöÄ Real-world Face Recognition Test")
    logger.info("=" * 60)
    
    ensure_output_dir()
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö API
    try:
        response = requests.get(f"{API_BASE_URL}/health", timeout=10)
        if response.status_code != 200:
            raise Exception("API server not ready")
        logger.info("‚úÖ API server is ready")
    except Exception as e:
        logger.error(f"‚ùå Cannot connect to API: {e}")
        return
    
    # ‡∏•‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    if not clear_database():
        logger.error("‚ùå Cannot access database")
        return
    
    try:
        # 1. ‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        logger.info("\nüìù Phase 1: User Registration")
        success_count, total_count = register_all_users()
        logger.info(f"‚úÖ Registration completed: {success_count}/{total_count}")
        
        # 2. ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏£‡∏π‡∏õ‡∏ó‡∏î‡∏™‡∏≠‡∏ö
        test_images = get_all_test_images()
        if not test_images:
            raise Exception("No test images found")
        
        logger.info(f"\nüéØ Phase 2: Recognition Testing ({len(test_images)} images)")
        
        # 3. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏î‡∏à‡∏≥
        test_results = {}
        error_count = 0
        unknown_count = 0
        
        for i, image_file in enumerate(test_images, 1):
            image_path = os.path.join(TEST_IMAGES_DIR, image_file)
            logger.info(f"\n[{i}/{len(test_images)}] Processing: {image_file}")
            
            try:
                # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô base64
                image_base64 = image_to_base64(image_path)
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
                faces = detect_faces(image_base64)
                if not faces:
                    logger.error(f"‚ùå No faces detected in {image_file}")
                    error_count += 1
                    if error_count >= 3:
                        raise Exception("Too many face detection failures")
                    continue
                
                logger.info(f"  üë§ Detected {len(faces)} face(s)")
                  # ‡∏à‡∏î‡∏à‡∏≥‡∏î‡πâ‡∏ß‡∏¢‡∏ó‡∏∏‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡∏™‡πà‡∏á faces ‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢)
                model_results = recognize_face_all_models(image_base64, faces)
                if not model_results:
                    logger.error(f"‚ùå Recognition failed for {image_file}")
                    error_count += 1
                    if error_count >= 3:
                        raise Exception("Too many recognition failures")
                    continue
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á Ensemble prediction
                ensemble_result = create_ensemble_prediction(model_results)
                model_results["ensemble"] = ensemble_result
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ó‡∏∏‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡πâ‡∏ú‡∏• unknown ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                all_unknown = True
                for model_name in MODELS:
                    if model_name in model_results:
                        matches = model_results[model_name].get("matches", [])
                        if matches:
                            all_unknown = False
                            break
                
                if all_unknown:
                    logger.error(f"‚ùå All models returned unknown for {image_file} - This is impossible!")
                    unknown_count += 1
                    if unknown_count >= 2:
                        raise Exception("Too many unknown results - system malfunction")
                    continue
                
                # ‡∏ß‡∏≤‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ö‡∏ô‡∏†‡∏≤‡∏û‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
                for model_name in MODELS + ["ensemble"]:
                    if model_name in model_results:
                        output_path = draw_results_on_image(image_path, faces, model_results[model_name], model_name)
                        if output_path:
                            logger.info(f"  üì∏ {model_name}: {os.path.basename(output_path)}")
                
                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                test_results[image_file] = {
                    "faces_detected": len(faces),
                    "model_results": model_results,
                    "processing_time": time.time()
                }
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                for model_name in MODELS:
                    if model_name in model_results:
                        matches = model_results[model_name].get("matches", [])
                        if matches:
                            best_match = matches[0]
                            logger.info(f"    üß† {model_name}: {best_match.get('person_id', 'unknown')} ({best_match.get('similarity', 0):.3f})")
                        else:
                            logger.info(f"    üß† {model_name}: unknown")
                
                # Ensemble result
                ensemble_matches = ensemble_result.get("matches", [])
                if ensemble_matches:
                    best_ensemble = ensemble_matches[0]
                    logger.info(f"    üèÜ Ensemble: {best_ensemble.get('person_id', 'unknown')} ({best_ensemble.get('similarity', 0):.3f})")
                else:
                    logger.info(f"    üèÜ Ensemble: unknown")
                
            except Exception as e:
                logger.error(f"‚ùå Error processing {image_file}: {e}")
                raise
        
        # 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏™‡∏£‡∏∏‡∏õ
        logger.info("\nüìä Generating final report...")
        generate_final_report(test_results)
        
        logger.info("üéâ Real-world test completed successfully!")
        
    except Exception as e:
        logger.error(f"üõë Test stopped due to error: {e}")
        raise

def generate_final_report(results: Dict[str, Any]):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•"""
    report = {
        "test_timestamp": time.strftime('%Y-%m-%d %H:%M:%S'),
        "total_images_processed": len(results),
        "models_tested": MODELS,
        "ensemble_weights": ENSEMBLE_WEIGHTS,
        "detailed_results": results,
        "summary": {}
    }
    
    # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    model_stats = {}
    
    for model_name in MODELS + ["ensemble"]:
        correct_boss = 0
        correct_night = 0
        unknown_count = 0
        total_processed = 0
        
        for image_file, image_results in results.items():
            model_result = image_results["model_results"].get(model_name, {})
            matches = model_result.get("matches", [])
            
            if matches:
                recognized = matches[0].get("person_id", "unknown")
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
                if "boss" in image_file.lower() and recognized == "boss":
                    correct_boss += 1
                elif "night" in image_file.lower() and recognized == "night":
                    correct_night += 1
                elif recognized == "unknown":
                    unknown_count += 1
            else:
                unknown_count += 1
            
            total_processed += 1
        
        accuracy = ((correct_boss + correct_night) / total_processed * 100) if total_processed > 0 else 0
        
        model_stats[model_name] = {
            "correct_boss": correct_boss,
            "correct_night": correct_night,
            "unknown_count": unknown_count,
            "total_processed": total_processed,
            "accuracy": accuracy
        }
    
    report["summary"] = model_stats
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô
    report_file = os.path.join(OUTPUT_DIR, "real_world_test_report.json")
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏£‡∏∏‡∏õ
    print_final_summary(model_stats)
    
    logger.info(f"üìÑ Detailed report saved: {report_file}")

def print_final_summary(stats: Dict[str, Any]):
    """‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö"""
    print("\n" + "="*80)
    print("üìä REAL-WORLD FACE RECOGNITION TEST RESULTS")
    print("="*80)
    print(f"üìÖ Test Date: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"üë• Users: boss, night (10 images each)")
    print(f"üß† Models: {', '.join(MODELS)} + Ensemble")
    print(f"‚öñÔ∏è Ensemble Weights: FACENET 50%, ADAFACE 25%, ARCFACE 25%")
    print("-"*80)
    
    for model_name, model_stats in stats.items():
        print(f"\nüî¨ {model_name.upper()} Results:")
        print(f"  ‚úÖ Boss Recognition: {model_stats['correct_boss']} correct")
        print(f"  ‚úÖ Night Recognition: {model_stats['correct_night']} correct")
        print(f"  ‚ùì Unknown Results: {model_stats['unknown_count']}")
        print(f"  üìä Overall Accuracy: {model_stats['accuracy']:.1f}%")
    
    # ‡∏´‡∏≤ model ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    best_model = max(stats.items(), key=lambda x: x[1]['accuracy'])
    print(f"\nüèÜ Best Model: {best_model[0].upper()} ({best_model[1]['accuracy']:.1f}% accuracy)")
    
    print(f"\nüìÅ Output images saved in: {OUTPUT_DIR}")
    print("   - Each model has its own folder")
    print("   - Images are saved at full resolution")
    print("   - Face boxes and names are drawn on images")

def crop_face_from_image(image_base64: str, face: Dict[str, Any]) -> str:
    """‡∏Ñ‡∏£‡∏≠‡∏õ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û base64 ‡πÉ‡∏ä‡πâ OpenCV ‡πÅ‡∏ó‡∏ô PIL"""
    try:
        # Decode base64 to numpy array
        image_data = base64.b64decode(image_base64)
        nparr = np.frombuffer(image_data, np.uint8)
        image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        if image is None:
            return ""
        
        # Get face coordinates
        bbox = face.get("bbox", {})
        x1 = int(bbox.get("x1", 0))
        y1 = int(bbox.get("y1", 0))
        x2 = int(bbox.get("x2", 0))
        y2 = int(bbox.get("y2", 0))
        
        # Add padding (10% of face size)
        width = x2 - x1
        height = y2 - y1
        padding_x = int(width * 0.1)
        padding_y = int(height * 0.1)
        
        # Expand bounding box with padding
        h, w = image.shape[:2]
        x1 = max(0, x1 - padding_x)
        y1 = max(0, y1 - padding_y)
        x2 = min(w, x2 + padding_x)
        y2 = min(h, y2 + padding_y)
        
        # Crop face
        cropped = image[y1:y2, x1:x2]
        
        # Convert back to base64
        _, encoded = cv2.imencode('.jpg', cropped, [cv2.IMWRITE_JPEG_QUALITY, 95])
        cropped_base64 = base64.b64encode(encoded.tobytes()).decode('utf-8')
        
        return cropped_base64
        
    except Exception as e:
        logger.warning(f"Cannot crop face: {e}")
        return ""

if __name__ == "__main__":
    try:
        run_real_world_test()
    except Exception as e:
        logger.error(f"üõë Test terminated: {e}")
        print(f"\nüõë TEST TERMINATED DUE TO ERROR: {e}")
        exit(1)
